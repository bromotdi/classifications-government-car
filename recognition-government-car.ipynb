{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e823f34",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-01-12T16:58:35.388814Z",
     "iopub.status.busy": "2024-01-12T16:58:35.388065Z",
     "iopub.status.idle": "2024-01-12T16:58:36.445142Z",
     "shell.execute_reply": "2024-01-12T16:58:36.444182Z"
    },
    "papermill": {
     "duration": 1.073727,
     "end_time": "2024-01-12T16:58:36.447577",
     "exception": false,
     "start_time": "2024-01-12T16:58:35.373850",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 12 16:58:36 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd4c3b",
   "metadata": {
    "papermill": {
     "duration": 0.012171,
     "end_time": "2024-01-12T16:58:36.472203",
     "exception": false,
     "start_time": "2024-01-12T16:58:36.460032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762ce6ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:58:36.497766Z",
     "iopub.status.busy": "2024-01-12T16:58:36.497435Z",
     "iopub.status.idle": "2024-01-12T16:58:48.903336Z",
     "shell.execute_reply": "2024-01-12T16:58:48.902028Z"
    },
    "papermill": {
     "duration": 12.420773,
     "end_time": "2024-01-12T16:58:48.904927",
     "exception": true,
     "start_time": "2024-01-12T16:58:36.484154",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     20\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from random import choice\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from datetime import datetime\n",
    "from torchvision import models, transforms\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d976813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:55:52.864642Z",
     "iopub.status.busy": "2024-01-12T16:55:52.864288Z",
     "iopub.status.idle": "2024-01-12T16:55:52.897561Z",
     "shell.execute_reply": "2024-01-12T16:55:52.896517Z",
     "shell.execute_reply.started": "2024-01-12T16:55:52.864606Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of file names\n",
    "images_special_car = listdir('/kaggle/input/dataset-for-classification-of-specialty-cars/Dataset/Spesial_car/') \n",
    "image_rest = listdir('/kaggle/input/dataset-for-classification-of-specialty-cars/Dataset/Rest/')\n",
    "\n",
    "# Transfer them to the dataframe\n",
    "data_special_car = pd.DataFrame(images_special_car, columns=['src'])\n",
    "data_rest = pd.DataFrame(image_rest, columns=['src'])\n",
    "\n",
    "# Add target attributes\n",
    "data_special_car['label'] = 1 # Specialty cars\n",
    "data_rest['label'] = 0 # Simple pictures\n",
    "\n",
    "# Объединяем \n",
    "data = pd.concat([data_special_car, data_rest], ignore_index=True)\n",
    "data # Let's take a look at the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8128a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:55:52.899317Z",
     "iopub.status.busy": "2024-01-12T16:55:52.898924Z",
     "iopub.status.idle": "2024-01-12T16:55:52.909094Z",
     "shell.execute_reply": "2024-01-12T16:55:52.908126Z",
     "shell.execute_reply.started": "2024-01-12T16:55:52.899287Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['label'].value_counts() / data.shape[0] * 100 # Распределение целевого признака"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1f630",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "You can see that there are more photos without specialty autos in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b2e28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2. Augmentation of photos and their subsequent processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5df71",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2.1. Description of augmentation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c4c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:55:52.911510Z",
     "iopub.status.busy": "2024-01-12T16:55:52.911194Z",
     "iopub.status.idle": "2024-01-12T16:55:52.920021Z",
     "shell.execute_reply": "2024-01-12T16:55:52.919124Z",
     "shell.execute_reply.started": "2024-01-12T16:55:52.911484Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Описываем приёмы аугментации\n",
    "transform1 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.05), # Поворот по вертикали\n",
    "    A.Blur(p=0.25) # Эффект размытия на изображении\n",
    "])\n",
    "transform2 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.05), # Поворот по вертикали\n",
    "    A.ToGray() # Перевод изображения в чб изображение\n",
    "])\n",
    "transform3 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5), # Поворот по вертикали\n",
    "    A.RandomContrast(p=0.25) # Увеличение контарстности\n",
    "])\n",
    "transform4 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.05), # Поворот по вертикали\n",
    "    A.JpegCompression(p=0.25) # Добавление шума на изображение\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756a87d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Processing of each photo and their augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f006c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:55:52.921411Z",
     "iopub.status.busy": "2024-01-12T16:55:52.921125Z",
     "iopub.status.idle": "2024-01-12T16:57:53.645201Z",
     "shell.execute_reply": "2024-01-12T16:57:53.643928Z",
     "shell.execute_reply.started": "2024-01-12T16:55:52.921386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = [] # Photographs in matrix format\n",
    "y = [] # Classes of photographs\n",
    "for i in tqdm(range(len(data))):\n",
    "    image = data.loc[i,'src'] # Get the path to the image\n",
    "    if (data.loc[i, 'label'] == 1): # If there's a special car in the picture\n",
    "        image = cv2.imread('/kaggle/input/dataset-for-classification-of-specialty-cars/Dataset/Spesial_car/'+image, cv2.IMREAD_COLOR) \n",
    "    else: # If it's not a special car in the picture\n",
    "        image = cv2.imread('/kaggle/input/dataset-for-classification-of-specialty-cars/Dataset/Rest/'+image, cv2.IMREAD_COLOR) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert the color palette of the photo from BGR to RGB \n",
    "    image = cv2.resize(image, dsize=(256, 256), interpolation=cv2.INTER_AREA) # Resize the image \n",
    "    X.append(image) # Adding to the dataset\n",
    "\n",
    "    # We're augmenting the photos\n",
    "    transform = None\n",
    "    transform_old = None\n",
    "    for _ in range(2):\n",
    "        while True:\n",
    "            transform = choice([transform1, transform2, transform3, transform4])\n",
    "            if transforms != transform_old:\n",
    "                transformed_image = transform(image=image)\n",
    "                X.append(transformed_image[\"image\"])\n",
    "                transform_old = transform\n",
    "                break\n",
    "    # Add labels for images\n",
    "    for _ in range(3):\n",
    "        y.append(data.loc[i, 'label'])\n",
    "\n",
    "# Normalize the data\n",
    "X_torch = np.array(X)\n",
    "X_torch = X_torch.astype('float32')\n",
    "X_torch = X_torch / 255.0\n",
    "X_torch = X_torch.reshape(-1,3, 256, 256)\n",
    "y_torch = np.array(y).reshape(-1)\n",
    "\n",
    "# Let's take a couple of examples of the resulting photos\n",
    "fig, axes = plt.subplots(1, 4, figsize=(30,15))\n",
    "for i in range(0, 4):\n",
    "    axes[i].imshow(X[i*y_torch.size//4])\n",
    "    axes[i].set_title(y[i*y_torch.size//4], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df8820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T16:57:53.648186Z",
     "iopub.status.busy": "2024-01-12T16:57:53.647358Z",
     "iopub.status.idle": "2024-01-12T16:57:53.653833Z",
     "shell.execute_reply": "2024-01-12T16:57:53.652808Z",
     "shell.execute_reply.started": "2024-01-12T16:57:53.648152Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of Iterations: {X_torch.shape[0]} | Number of tags {y_torch.size}\")\n",
    "print(f\"The number of photos after augmentation increased {round(y_torch.size / data.shape[0], 3)} times to {y_torch.size} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b57693",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 3. Neural network training\n",
    "## 3.1. Formation of training and validation sample, translation of data into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503ef60",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define the possibility of photo processing on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b6b43",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Form a new training and test sample\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_torch, y_torch, random_state=42)\n",
    "# Let's convert all the data into tensors\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train)\n",
    "X_valid_t = torch.from_numpy(X_valid).float()\n",
    "y_valid_t = torch.from_numpy(y_valid)\n",
    "\n",
    "# Generate datasets with samples\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "valid_dataset = TensorDataset(X_valid_t, y_valid_t)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Dictionary with selections\n",
    "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c05100",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.2. Functions for training, saving, visualizing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea74a13",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainNeuralNetwork(model, loaders, name_model, max_epochs, epoch_patience):\n",
    "    '''\n",
    "    The function allows you to train a neural network model, store the weights on the computer and return the execution history\n",
    "    Input:\n",
    "        model - neural network model\n",
    "        loaders - dictionary with samples\n",
    "        name_model - model name\n",
    "        max_epochs - maximum number of training epochs\n",
    "        epoch_patience - number of epochs for early stopping of training (fight against overtraining)\n",
    "    Output:\n",
    "        best_model_roc - true and predicted values from the best model \n",
    "        loss_history - history of error by epochs during model training\n",
    "        epoch_erly_stopping - epoch at which the early model stopping occurred\n",
    "        best_model_accuracy - accuracy of the best model instance\n",
    "        best_model_loss - loss of the best model instance\n",
    "    '''\n",
    "    print(f'Training of {name_model} neural network architecture')\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Error calculation\n",
    "    optimizer = torch.optim.Adam(model.parameters()) # Calculating the loss gradient\n",
    "    scheduler = StepLR(optimizer, step_size=25, gamma=0.1) \n",
    "    best_model = model # The best looking model\n",
    "    best_model_loss = np.Inf # Loss at the best model\n",
    "    best_model_accuracy = 0 # Accuracy with the best model  \n",
    "    epoch_erly_stopping = 0 # The era of the early shutdown\n",
    "    flag = False \n",
    "    col_not_best = 0 # Number of epochs unchanged\n",
    "    loss_history = {\"train\": [], \"valid\": []}  # The history of model loss at each epoch\n",
    "    best_model_roc = {\"correct\": [], \"preds\": []} # ROC curve calculation data of the best model \n",
    "    train_losses = [] # Loss on the training sample for each picture\n",
    "    valid_losses = [] # Loss on the validation sample for each picture\n",
    "    start_time = datetime.now() # Start time\n",
    "    for epoch in range(max_epochs):\n",
    "        for k, dataloader in loaders.items():\n",
    "            epoch_correct = 0\n",
    "            epoch_all = 0\n",
    "            roc = {\"correct\": [], \"preds\": []}\n",
    "            for x_batch, y_batch in dataloader:\n",
    "                # Transfer the data to the device\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                if k == \"train\":\n",
    "                    model.train() # Putting the model in training \n",
    "                    optimizer.zero_grad() # Zero out the error gradients\n",
    "                    outp = model(x_batch) # Getting answers from the model\n",
    "                else:\n",
    "                    model.eval() # Set the model to predict\n",
    "                    with torch.no_grad():\n",
    "                        outp = model(x_batch)\n",
    "                preds = outp.argmax(-1) \n",
    "                correct = (preds == y_batch).sum()  # Number of correct answers\n",
    "                all = preds.size(0) # Number of all responses\n",
    "                epoch_correct += correct.item() # Number of photos correctly recognized\n",
    "                epoch_all += all \n",
    "                loss = criterion(outp, y_batch) # Calculate the loss gradient\n",
    "                if k == \"train\":\n",
    "                    train_losses.append(loss.item()) \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    roc[\"correct\"].append([i.item() for i in y_batch])\n",
    "                    roc[\"preds\"].append([i.item() for i in preds])\n",
    "                    valid_losses.append(loss.item()) \n",
    "                    \n",
    "            if k == \"valid\":\n",
    "                # Calculate the weighted average of the samples\n",
    "                train_loss = np.average(train_losses) \n",
    "                valid_loss = np.average(valid_losses) \n",
    "                \n",
    "                # Save the weighted average error to history\n",
    "                loss_history[\"train\"].append(abs(train_loss))\n",
    "                loss_history[\"valid\"].append(abs(valid_loss))\n",
    "                print(f\"[{epoch+1:>3}/{max_epochs:>3}] loss train: {abs(train_loss):.5f} | loss valid: {abs(valid_loss):.5f}\")\n",
    "\n",
    "                # Checking for neural network error reduction on validation\n",
    "                if abs(round(best_model_loss, 5)) > abs(round(valid_loss, 5)):\n",
    "                    # Saving model information and weights\n",
    "                    col_not_best = 0 \n",
    "                    best_model = model\n",
    "                    epoch_erly_stopping = epoch\n",
    "                    best_model_accuracy = epoch_correct/epoch_all \n",
    "                    best_model_roc = roc\n",
    "                    torch.save(best_model, f\"checkpoint_{name_model}.pt\")\n",
    "                    print(f\"Validation loss decreased ({abs(best_model_loss):.5f} --> {abs(valid_loss):.5f}).  Saving model ...\")\n",
    "                    best_model_loss = abs(valid_loss)\n",
    "                           \n",
    "                else:\n",
    "                    # If X number of epochs no progress, stop learning\n",
    "                    if col_not_best + 1 >= epoch_patience:\n",
    "                        print(\"Early stopping!\")\n",
    "                        flag = True\n",
    "                        break\n",
    "                    else:\n",
    "                        col_not_best += 1\n",
    "                        print(f\"EarlyStopping counter: {col_not_best} out of {epoch_patience}\")    \n",
    "        scheduler.step()\n",
    "        if flag:\n",
    "            break\n",
    "    roc = {'correct': [], 'preds': []}\n",
    "    for sampling in ['correct', 'preds']:\n",
    "        for index in range(len(best_model_roc[sampling])):\n",
    "            for item in best_model_roc[sampling][index]:\n",
    "                roc[sampling].append(item)\n",
    "    best_model_roc = roc\n",
    "    torch.save(best_model, f\"{name_model}.pth\") # Saving the complete model on the computer\n",
    "    print(f'Program execution time: {datetime.now() - start_time}')\n",
    "    return best_model_roc, loss_history, epoch_erly_stopping, best_model_accuracy, best_model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f9cf5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualizationLearning(name_model, epoch_stopping, roc, loss_history ):\n",
    "    '''\n",
    "    The function allows to visualize the training history of the neural network model and to show the early errors\n",
    "    Input:\n",
    "        name_model - model name \n",
    "        epoch_stopping - epoch at which the early stopping occurred \n",
    "        roc - true and predicted values\n",
    "        loss_history - history of model losses at each epoch\n",
    "    '''\n",
    "    plt.figure(figsize=(21, 9))\n",
    "    \n",
    "    # Loss history image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(loss_history[\"train\"], label='Training sample')\n",
    "    plt.plot(loss_history[\"valid\"], label='Validation sample')\n",
    "    plt.title(f'CrossEntropyLoss architecture {name_model}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('')\n",
    "    plt.axvline(epoch_stopping, color='red', linestyle='--', label='EarlyStopping')\n",
    "    plt.legend()\n",
    "   \n",
    "    # ROC curve image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    fpr, tpr, _ = roc_curve(roc['correct'], roc['preds'])\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') \n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.title(f'ROC Curves architecture {name_model}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save it to an image and render it\n",
    "    plt.savefig(f'{name_model}.png',dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf2338",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualizationNeuralNetworks(data, isEnhancement=False):\n",
    "    '''\n",
    "    The function allows you to visualize the accuracy of the neural network models at each epoch and put them all on the same graph\n",
    "    Input:\n",
    "        data - array containing dictionaries with data for each neural network\n",
    "    The function allows visualizing the accuracy of neural network models at each of the epochs and placing all of them on one graph\n",
    "    Input:\n",
    "        data - array containing dictionaries with data for each neural network\n",
    "    '''\n",
    "    plt.figure(figsize=(21, 9))\n",
    "    max_epoch = 0\n",
    "    for item in data:\n",
    "        # Loss history image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(item['loss_history']['valid'], label=item['name'])\n",
    "        plt.title('CrossEntropyLoss of neural networks')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('CrossEntropyLoss')\n",
    "        plt.legend()\n",
    "\n",
    "        # ROC curve image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        fpr, tpr, _ = roc_curve(item['roc_data']['correct'], item['roc_data']['preds'])\n",
    "        area = auc(fpr, tpr)\n",
    "        label_model = item['name']+ f' (area = {area:0.2f})'\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=label_model)\n",
    "        plt.plot([0, 1], [0, 1], 'k--') \n",
    "        plt.title('ROC Curves of neural networks')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    if isEnhancement:\n",
    "        plt.savefig(f'{isEnhancement}.png', dpi=100)\n",
    "    else:\n",
    "        plt.savefig(f'visualizationNeuralNetworks.png', dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e599744",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addHistoryModels(name, roc, loss_history, loss, epoch_stopping ):\n",
    "    '''\n",
    "    The function allows you to write all information about model training to a json file\n",
    "    Input:\n",
    "        name - model name \n",
    "        roc - true and predicted values of the best model \n",
    "        loss_history - history of model losses at each of the epochs  \n",
    "        accuracy - accuracy of the best model instance  \n",
    "        loss - loss of the best model instance \n",
    "        epoch_stopping - epoch on which the early stopping occurred\n",
    "    \n",
    "    '''\n",
    "    if 'data.json' not in os.listdir():\n",
    "        json_data = [{'name': name,\n",
    "                      'loss_history': loss_history,\n",
    "                      'loss': loss,\n",
    "                      'epoch_stopping':epoch_erly_stopping,\n",
    "                      'roc_data': roc  \n",
    "        }]\n",
    "        with open('data.json', 'w') as file:\n",
    "            json.dump(json_data, file)\n",
    "    else:\n",
    "        with open('data.json', 'r') as file:\n",
    "            json_data = json.load(file)  # Load the contents of the file into the dictionary\n",
    "        isDublicate = False\n",
    "        for i in range(len(json_data)):\n",
    "            if json_data[i]['name'] == name:\n",
    "                json_data[i] = {'name': name,\n",
    "                    'loss_history': loss_history,\n",
    "                    'loss': loss,\n",
    "                    'epoch_stopping':epoch_erly_stopping,\n",
    "                    'roc_data': roc     \n",
    "                }\n",
    "                print('Model training data successfully overwritten')\n",
    "                isDublicate = True\n",
    "                break\n",
    "        else:\n",
    "            json_data.append({\n",
    "                'name': name,        \n",
    "                'loss_history': loss_history,\n",
    "                'loss': loss,\n",
    "                'epoch_stopping':epoch_erly_stopping,\n",
    "                'roc_data': roc         \n",
    "            })\n",
    "            print('Model training data successfully recorded')\n",
    "    with open('data.json', 'w') as file:\n",
    "            json.dump(json_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7dafb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs_models = 100 # Maximum number of epochs\n",
    "epoch_patience_models = 15 # The tolerance of the ages to an early halt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04af644",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.2. Training of MobileNetV3Large neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05402a22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_large() # Loading structure and weights\n",
    "model.classifier = torch.nn.Linear(960, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'MobileNetV3Large'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model ,loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d433c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.3. Training of EffecientNet_B0 neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf2592",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0() # Loading structure and weights\n",
    "model.classifier = torch.nn.Linear(1280, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'EffecientNet_B0'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a7359",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.4. Training of MNASNET1_3 neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575a58a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.mnasnet1_3() # Loading structure and weights\n",
    "model.classifier =  torch.nn.Linear(1280, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'MNASNET1_3'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098188bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.5. Training of the ResNet18 neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cbf66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet18() # Loading structure and weights\n",
    "model.fc = torch.nn.Linear(512, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'ResNet18'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b8752",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.6. Training of YOLOv5 neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6bcd3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load(\n",
    "    \"ultralytics/yolov5\", \"custom\", \"yolov5s-cls.pt\"\n",
    ") # Loading structure and weights\n",
    "model.model.model[-1].linear = torch.nn.Linear(1280, 1) # Prediction layer replacement\n",
    "model = model.model\n",
    "model.to(device)\n",
    "name_model = 'YOLOv5s'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d707b0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.7. Training of YOLOv8 neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c7053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt') # Loading structure and weights\n",
    "model.model.model[-1].linear = torch.nn.Linear(1280, 1) # Prediction layer replacement\n",
    "model = model.model\n",
    "model.to(device)\n",
    "name_model = 'YOLOv8n'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98e8cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.8. Training of REGNET_X_1_6GF neural network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c501d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.regnet_y_1_6gf() # Loading structure and weights\n",
    "model.fc = torch.nn.Linear(888, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'RegNet_y_1_6gf'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d307b21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3.9 Visualize all models on one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e382fc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "visualizationNeuralNetworks(data[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7614a1c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "From the outcome of neural network training, it can be seen that the ResNet architecture has better performance on the ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439954b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 4. Exploring different versions of the ResNet architecture\n",
    "## 4.1. Training the ResNet34 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b14e7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet34() # Loading structure and weights\n",
    "model.fc = torch.nn.Linear(512, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'ResNet34'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5aa8f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Training the ResNet50 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11278f50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet50() # Loading structure and weights\n",
    "model.fc = torch.nn.Linear(2048, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'ResNet50'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models) \n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d1cd0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4.3. Visualization of ResNet architecture version training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2628f40",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "resnet_data = []\n",
    "for index in range(len(data)):\n",
    "    if data[index]['name'].find('ResNet') != -1:\n",
    "        resnet_data.append(data[index])\n",
    "visualizationNeuralNetworks(resnet_data, isEnhancement='VisualizationResNetVersion')\n",
    "del data, resnet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f09b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "According to the training results of different versions of the ResNet neural network architecture, the ResNet18 version has the best performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bbc0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 5. Learning the best architecture for neroset\n",
    "## 5.1. Let's apply all augmentations to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b403a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = [] # Photographs in matrix format\n",
    "y = [] # Classes of photographs\n",
    "for i in tqdm(range(len(data))):\n",
    "    image = data.loc[i,'src'] # Get the path to the image\n",
    "    if (data.loc[i, 'label'] == 1): # If there's a special car in the picture\n",
    "        image = cv2.imread('./Dataset/Spesial_car/'+image, cv2.IMREAD_COLOR) \n",
    "    else: # If it's not a special car in the picture\n",
    "        image = cv2.imread('./Dataset/Rest/'+image, cv2.IMREAD_COLOR) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert the color palette of the photo from BGR to RGB \n",
    "    image = cv2.resize(image, dsize=(256, 256), interpolation=cv2.INTER_AREA) # Resize the image\n",
    "    X.append(image) # Add to the dataset\n",
    "    # We're augmenting the photos\n",
    "    for transform in [transform1, transform2, transform3, transform4]:\n",
    "        transformed_image = transform(image=image)\n",
    "        X.append(transformed_image[\"image\"])\n",
    "    # Add labels for images\n",
    "    for _ in range(5):\n",
    "        y.append(data.loc[i, 'label'])\n",
    "\n",
    "# Normalize the data\n",
    "X_torch = np.array(X)\n",
    "X_torch = X_torch.astype('float32')\n",
    "X_torch = X_torch / 255.0\n",
    "X_torch = X_torch.reshape(-1,3, 256, 256)\n",
    "y_torch = np.array(y).reshape(-1)\n",
    "\n",
    "# Let's take a couple of examples of the resulting photos\n",
    "fig, axes = plt.subplots(1, 4, figsize=(30,15))\n",
    "for i in range(0, 4):\n",
    "    axes[i].imshow(X[i*y_torch.size//4])\n",
    "    axes[i].set_title(y[i*y_torch.size//4], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193579b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of Isorations: {X_torch.shape[0]} | Number of tags {y_torch.size}\")\n",
    "print(f\"The number of photos after augmentation increased {round(y_torch.size / data.shape[0], 3)} times to {y_torch.size} images\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd245027",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5.2. Formation of training and validation sample, translation of data into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dc122",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Form a new training and test sample\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_torch, y_torch, random_state=42)\n",
    "# Let's convert all the data into tensors\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train)\n",
    "X_valid_t = torch.from_numpy(X_valid).float()\n",
    "y_valid_t = torch.from_numpy(y_valid)\n",
    "\n",
    "# Generate datasets with samples\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "valid_dataset = TensorDataset(X_valid_t, y_valid_t)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Dictionary with selections\n",
    "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c1c78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5.3. Training the best version of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf3976",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs_models = 350 # Maximum number of epochs\n",
    "epoch_patience_models = 25 # The tolerance of the ages to an early halt\n",
    "model = models.resnet18(pretrained=True) # Loading structure and weights pretrained model\n",
    "model.fc = torch.nn.Linear(512, 1) # Prediction layer replacement\n",
    "model.to(device)\n",
    "name_model = 'ResNet18-top'\n",
    "roc, loss_history, epoch_erly_stopping, loss  = trainNeuralNetwork(\n",
    "    model, loaders, name_model, max_epochs_models, epoch_patience_models, lr=0.0001)\n",
    "addHistoryModels(name_model, roc, loss_history, loss, epoch_erly_stopping)\n",
    "visualizationLearning(name_model, epoch_erly_stopping, roc, loss_history)\n",
    "del model, loss_history, epoch_erly_stopping, loss, name_model, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7a63a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d4a2b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "resnet_data = []\n",
    "for index in range(len(data)):\n",
    "    if data[index]['name'].find('ResNet18') != -1:\n",
    "        resnet_data.append(data[index])\n",
    "visualizationNeuralNetworks(resnet_data, isEnhancement='VisualizationTratingResNet18')\n",
    "del data, resnet_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ba27b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "As a result of applying full augmentation to all images, we were able to improve the performance of the neural network."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4111608,
     "sourceId": 7363733,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 4621,
     "sourceId": 6112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 4603,
     "sourceId": 6120,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 1911,
     "sourceId": 2645,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 137,
     "sourceId": 193,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.512913,
   "end_time": "2024-01-12T16:58:51.099433",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-12T16:58:30.586520",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
